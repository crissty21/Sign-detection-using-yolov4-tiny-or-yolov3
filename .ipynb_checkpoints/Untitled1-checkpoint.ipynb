{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42433c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fc0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('videos/traffic-sign-to-test.mp4')\n",
    "\n",
    "writer = None\n",
    "h, w = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e86115",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cfg\\classes.names') as f:\n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "# Loading trained YOLO\n",
    "network = cv2.dnn.readNetFromDarknet('cfg\\yolov4-tiny.cfg',\n",
    "                                     'cfg\\yolov4-tiny.weights')\n",
    "\n",
    "layers_names_all = network.getLayerNames()\n",
    "\n",
    "# Getting only output layers' names that we need from YOLO v3 algorithm\n",
    "# with function that returns indexes of layers with unconnected outputs\n",
    "layers_names_output = \\\n",
    "    [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "# Setting minimum probability to eliminate weak predictions\n",
    "probability_minimum = 0.5\n",
    "\n",
    "# Setting threshold for filtering weak bounding boxes with non-maximum suppression\n",
    "threshold = 0.3\n",
    "\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667c87a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame number 1 took 0.10210 seconds\n",
      "Frame number 2 took 0.03806 seconds\n",
      "Frame number 3 took 0.03706 seconds\n",
      "Frame number 4 took 0.04417 seconds\n",
      "Frame number 5 took 0.04508 seconds\n",
      "Frame number 6 took 0.03968 seconds\n",
      "Frame number 7 took 0.04139 seconds\n",
      "Frame number 8 took 0.04308 seconds\n",
      "Frame number 9 took 0.03860 seconds\n",
      "Frame number 10 took 0.03909 seconds\n",
      "Frame number 11 took 0.03762 seconds\n",
      "Frame number 12 took 0.03756 seconds\n",
      "Frame number 13 took 0.03608 seconds\n",
      "Frame number 14 took 0.03698 seconds\n",
      "Frame number 15 took 0.03857 seconds\n",
      "Frame number 16 took 0.03827 seconds\n",
      "Frame number 17 took 0.04008 seconds\n",
      "Frame number 18 took 0.20336 seconds\n",
      "Frame number 19 took 0.07463 seconds\n",
      "Frame number 20 took 0.05259 seconds\n",
      "Frame number 21 took 0.04559 seconds\n",
      "Frame number 22 took 0.03663 seconds\n",
      "Frame number 23 took 0.03808 seconds\n",
      "Frame number 24 took 0.03809 seconds\n",
      "Frame number 25 took 0.04107 seconds\n",
      "Frame number 26 took 0.03707 seconds\n",
      "Frame number 27 took 0.03807 seconds\n",
      "Frame number 28 took 0.04007 seconds\n",
      "Frame number 29 took 0.03859 seconds\n",
      "Frame number 30 took 0.03656 seconds\n",
      "Frame number 31 took 0.03655 seconds\n",
      "Frame number 32 took 0.04361 seconds\n",
      "Frame number 33 took 0.04275 seconds\n",
      "Frame number 34 took 0.04366 seconds\n",
      "Frame number 35 took 0.04108 seconds\n",
      "Frame number 36 took 0.04108 seconds\n",
      "Frame number 37 took 0.05311 seconds\n",
      "Frame number 38 took 0.03758 seconds\n",
      "Frame number 39 took 0.03859 seconds\n",
      "Frame number 40 took 0.03807 seconds\n",
      "Frame number 41 took 0.03809 seconds\n",
      "Frame number 42 took 0.03656 seconds\n",
      "Frame number 43 took 0.03806 seconds\n",
      "Frame number 44 took 0.03909 seconds\n",
      "Frame number 45 took 0.03759 seconds\n",
      "Frame number 46 took 0.03797 seconds\n",
      "Frame number 47 took 0.03908 seconds\n",
      "Frame number 48 took 0.03807 seconds\n",
      "Frame number 49 took 0.08316 seconds\n",
      "Frame number 50 took 0.12773 seconds\n",
      "Frame number 51 took 0.12623 seconds\n",
      "Frame number 52 took 0.06013 seconds\n",
      "Frame number 53 took 0.03647 seconds\n",
      "Frame number 54 took 0.03707 seconds\n",
      "Frame number 55 took 0.04167 seconds\n",
      "Frame number 56 took 0.03606 seconds\n",
      "\n",
      "Total number of frames 56\n",
      "Total amount of time 2.72297 seconds\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "t = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    if w is None or h is None:\n",
    "        # Slicing from tuple only first two elements\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "\n",
    "    # Getting blob from current frame\n",
    "    # The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob from current\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                                 swapRB=True, crop=False)\n",
    "\n",
    "\n",
    "\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "\n",
    "    # Increasing counters for frames and total time\n",
    "    f += 1\n",
    "    t += end - start\n",
    "\n",
    "    print('Frame number {0} took {1:.5f} seconds'.format(f, end - start))\n",
    "\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    for result in output_from_network:\n",
    "        for detected_objects in result:\n",
    "            \n",
    "            scores = detected_objects[5:]\n",
    "            # Getting index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Getting value of probability for defined class\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            # Eliminating weak predictions with minimum probability\n",
    "            if confidence_current > probability_minimum:\n",
    "                # Scaling bounding box coordinates to the initial frame size\n",
    "                # YOLO data format keeps coordinates for center of bounding box\n",
    "                # and its current width and height\n",
    "                # That is why we can just multiply them elementwise\n",
    "                # to the width and height\n",
    "                # of the original frame and in this way get coordinates for center\n",
    "                # of bounding box, its width and height for original frame\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Now, from YOLO data format, we can get top left corner coordinates\n",
    "                # that are x_min and y_min\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Adding results into prepared lists\n",
    "                bounding_boxes.append([x_min, y_min,\n",
    "                                       int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "\n",
    "    # Implementing non-maximum suppression of given bounding boxes\n",
    "    # With this technique we exclude some of bounding boxes if their\n",
    "    # corresponding confidences are low or there is another\n",
    "    # bounding box for this region with higher confidence\n",
    "\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
    "                               probability_minimum, threshold)\n",
    "\n",
    "\n",
    "    if len(results) > 0:\n",
    "        for i in results.flatten():\n",
    "            # Getting current bounding box coordinates,\n",
    "            # its width and height\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "            cv2.rectangle(frame, (x_min, y_min),\n",
    "                          (x_min + box_width, y_min + box_height),\n",
    "                          colour_box_current, 2)\n",
    "\n",
    "            # Preparing text with label and confidence for current bounding box\n",
    "            text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                                   confidences[i])\n",
    "            \n",
    "            cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour_box_current, 2)\n",
    "\n",
    "\n",
    "    if writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter('videos/result-traffic-cars.mp4', fourcc, 30,\n",
    "                                 (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print('Total number of frames', f)\n",
    "print('Total amount of time {:.5f} seconds'.format(t))\n",
    "#print('FPS:', round((f / t), 1))\n",
    "\n",
    "\n",
    "# Releasing video reader and writer\n",
    "video.release()\n",
    "writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48974d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "udemy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
